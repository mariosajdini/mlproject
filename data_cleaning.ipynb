{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook I will process the thesaurus dataset and extract the words and phrases from it. I got the thesaurus in pure text format from the following link: https://www.gutenberg.org/ebooks/10681. I choose this format and i will process it with a mixed strategy ofregex and utilizing llms that you will see in the following cells."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c6fee1d23e43c62"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "import json "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.579797Z",
     "start_time": "2024-02-24T21:34:46.578085Z"
    }
   },
   "id": "914ac9af78c18a57",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.585640Z",
     "start_time": "2024-02-24T21:34:46.579990Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pg10681.txt', 'r', encoding='utf-8') as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I used a strategy that find the classes of the thesaurus and gets the text of each class. Then i broke this strategy into smaller parts to get the divisions and sections of each class. I used regex to find the classes, divisions and sections. I also used a strategy to find the words and phrases in the sections. I will show the code for each part in the following cells."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "517c58f244bc1835"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first part is to extract the classes from the thesaurus and their text. I used the following code to do this."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ce5349f45d5cf4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_classes_with_text(text):\n",
    "    class_pattern = r'(CLASS\\s+[IVXLCDM]+\\n[^\\n]+)'  # Pattern to match class titles\n",
    "    end_marker = \"End of E-Thesaurus\"  # Define the end marker\n",
    "    \n",
    "    # Find all class titles and their positions\n",
    "    classes = [(match.group(), match.end()) for match in re.finditer(class_pattern, text)]\n",
    "    \n",
    "    # Add an artificial end marker for the last class to simplify logic\n",
    "    if re.search(end_marker, text):\n",
    "        classes.append((\"END\", re.search(end_marker, text).start()))\n",
    "    else:\n",
    "        classes.append((\"END\", len(text)))\n",
    "    \n",
    "    class_dict = {}\n",
    "    # Iterate through classes to assign text to each class\n",
    "    for i in range(len(classes) - 1):\n",
    "        class_title = classes[i][0].strip()\n",
    "        start_index = classes[i][1]\n",
    "        end_index = classes[i + 1][1]\n",
    "        # Extract text for the current class\n",
    "        class_text = text[start_index:end_index].strip()\n",
    "        class_dict[class_title] = class_text\n",
    "    \n",
    "    return class_dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.598836Z",
     "start_time": "2024-02-24T21:34:46.585980Z"
    }
   },
   "id": "42fc35ddb50ab908",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Method to remove newlines from dictionary keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ae6be8170124e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_newlines_from_dict_keys(input_dict):\n",
    "    modified_dict = {key.replace('\\n', ': '): value for key, value in input_dict.items()}\n",
    "    return modified_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.599131Z",
     "start_time": "2024-02-24T21:34:46.588144Z"
    }
   },
   "id": "d4d851c9671cf12d",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same idea as before in order to extract the divisions of each class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e2d496891c12c60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_divisions(class_dict):\n",
    "    division_pattern = r\"DIVISION\\s(?:I|V|X|L|C|D|M)+\\n[A-Z\\s]+\\n\"  # Regex pattern for division titles\n",
    "\n",
    "    for class_title, class_text in class_dict.items():\n",
    "        # Find all division titles and their positions\n",
    "        divisions = [(match.group().strip(), match.end()) for match in re.finditer(division_pattern, class_text)]\n",
    "        \n",
    "        # Handle case with no divisions\n",
    "        if not divisions:\n",
    "            class_dict[class_title] = {\"NO_DIVISION\": class_text}\n",
    "            continue\n",
    "\n",
    "        # Add an artificial end marker for the last division to simplify logic\n",
    "        divisions.append((\"END\", len(class_text)))\n",
    "\n",
    "        division_dict = {}\n",
    "        # Iterate through divisions to assign text to each division\n",
    "        for i in range(len(divisions) - 1):\n",
    "            division_title = divisions[i][0].strip()\n",
    "            start_index = divisions[i][1]\n",
    "            end_index = divisions[i + 1][1]\n",
    "            # Extract text for the current division\n",
    "            division_text = class_text[start_index:end_index].strip()\n",
    "            division_dict[division_title] = division_text\n",
    "\n",
    "        # Update the class in the dictionary with its divisions\n",
    "        class_dict[class_title] = division_dict\n",
    "\n",
    "    return class_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.599317Z",
     "start_time": "2024-02-24T21:34:46.591175Z"
    }
   },
   "id": "230818fae16975d6",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same idea as before in order to extract the sections of each division."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583f312b8dcee835"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def refine_section_extraction(class_dict):\n",
    "    # Pattern to match section identifiers and optional descriptive titles\n",
    "    full_section_pattern = r'(SECTION\\s+[IVXLCDM]+\\.)\\s*([^\\n]*)'\n",
    "    \n",
    "    for class_title, divisions in class_dict.items():\n",
    "        for division_title, division_text in divisions.items():\n",
    "            # Temporary dictionary to store sections for the current division\n",
    "            temp_section_dict = {}\n",
    "            \n",
    "            # Find all matches for the full section pattern\n",
    "            matches = list(re.finditer(full_section_pattern, division_text))\n",
    "            \n",
    "            for i, match in enumerate(matches):\n",
    "                # Determine the start of the next match or use the end of the division text if at the last match\n",
    "                end_index = matches[i + 1].start() if i + 1 < len(matches) else len(division_text)\n",
    "                \n",
    "                # Extract the full section title, combining the identifier and the optional descriptive title\n",
    "                full_section_title = match.group(1) + (' ' + match.group(2).strip() if match.group(2).strip() else '')\n",
    "                # Extract the text for this section\n",
    "                section_text = division_text[match.end():end_index].strip()\n",
    "                \n",
    "                temp_section_dict[full_section_title] = section_text\n",
    "            \n",
    "            # If no sections were found, use a placeholder\n",
    "            if not temp_section_dict:\n",
    "                temp_section_dict[\"NO_SECTION\"] = division_text\n",
    "            \n",
    "            # Update the division entry with its sections\n",
    "            divisions[division_title] = temp_section_dict\n",
    "\n",
    "    return class_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.599488Z",
     "start_time": "2024-02-24T21:34:46.592277Z"
    }
   },
   "id": "8d7ca1debc247711",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following method is used to process sections with title like this: \"1. BEING, IN THE ABSTRACT\" and no title key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "134bb0482147430d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_sections_with_no_title_key(class_dict):\n",
    "    # Adjusted pattern for subsection titles within the section text\n",
    "    adjusted_pattern_for_subsections = r'^\\d\\.\\s?([A-Z]+([,\\s]+[A-Z]+)*([,\\s]+[a-z]+)*)*$'\n",
    "\n",
    "    for class_title, divisions in class_dict.items():\n",
    "        for division_title, sections in divisions.items():\n",
    "            updated_sections = {}\n",
    "            for section_title, section_text in sections.items():\n",
    "                # Attempt to capture the full section title and text excluding this title\n",
    "                full_title_search = re.search(r'(SECTION\\s+[IVXLCDM]+\\.)\\s*([^\\n]+)', section_text)\n",
    "                if full_title_search:\n",
    "                    full_section_title = full_title_search.group(1) + \" \" + full_title_search.group(2).strip()\n",
    "                    section_text_without_title = section_text[len(full_section_title):].strip()\n",
    "                else:\n",
    "                    full_section_title = section_title\n",
    "                    section_text_without_title = section_text\n",
    "\n",
    "                titles_matches = list(re.finditer(adjusted_pattern_for_subsections, section_text_without_title, re.MULTILINE))\n",
    "                if titles_matches:\n",
    "                    title_dict = {}\n",
    "                    for k in range(len(titles_matches)):\n",
    "                        title = titles_matches[k].group(0).strip()\n",
    "                        title_start_index = titles_matches[k].end()\n",
    "                        title_end_index = titles_matches[k + 1].start() if k + 1 < len(titles_matches) else len(section_text_without_title)\n",
    "                        subsection_text = section_text_without_title[title_start_index:title_end_index].strip()\n",
    "                        title_dict[title] = subsection_text\n",
    "\n",
    "                    updated_sections[full_section_title] = title_dict\n",
    "                else:\n",
    "                    updated_sections[full_section_title] = {\"NO_TITLE\": section_text_without_title}\n",
    "\n",
    "            divisions[division_title] = updated_sections\n",
    "\n",
    "    return class_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.606807Z",
     "start_time": "2024-02-24T21:34:46.597316Z"
    }
   },
   "id": "6e1f1a3947de8059",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "The text between the titles had some subtitles that were not needed. I used the following method to remove them. They looked like this \"3. FORMAL EXISTENCE Internal conditions\". So this method removes the first two lines of the text if the text does not start with a number. So if it has text like \"Internal conditions\" it will remove the first two lines."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3300b14ccdabc508"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def transform_title_values(class_dict):\n",
    "    for class_title, divisions in class_dict.items():\n",
    "        for division_title, sections in divisions.items():\n",
    "            for section_title, section in sections.items():\n",
    "                for title, text in section.items():\n",
    "                    # Determine if the text starts with a number\n",
    "                    if not text.strip().startswith(tuple('0123456789')):\n",
    "                        lines = text.splitlines()\n",
    "                        remaining_lines = lines[2:]\n",
    "                        text = '\\n'.join(remaining_lines)  # Rejoin the remaining lines\n",
    "                    \n",
    "                    # Define the section pattern for splitting the text\n",
    "                    section_pattern = r'(?=\\n\\d+[a-z]?\\. )'\n",
    "                    # Split the text into sections\n",
    "                    sections = re.split(section_pattern, text)\n",
    "                    \n",
    "                    # Update the text for the title with the processed sections\n",
    "                    section[title] = sections\n",
    "\n",
    "    return class_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.607879Z",
     "start_time": "2024-02-24T21:34:46.600199Z"
    }
   },
   "id": "6a89e163ea12b452",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Method that exports the dictionary to a json file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f27c5980aeef1778"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def write_data_to_json_file(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.608067Z",
     "start_time": "2024-02-24T21:34:46.602388Z"
    }
   },
   "id": "76c16fe72deaf92e",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code is used to extract the words and phrases from classes, divisions and sections. This creates an output like the thesaurus.json file. Then this have text like this \n",
    "\n",
    "`3. Substantiality -- N. substantiality, hypostasis; person, being,\n",
    "thing, object, article, item; something, a being, an existence;\n",
    "creature, body, substance, flesh and blood, stuff, substratum; matter\n",
    "&c 316; corporeity^, element, essential nature, groundwork, materiality,\n",
    "substantialness, vital part.\n",
    "     [Totality of existences], world &c 318; plenum.\n",
    "Adj. substantive, substantial; hypostatic; personal, bodily, tangible\n",
    "&c (material) 316; corporeal.\n",
    "Adv. substantially &c adj.; bodily, essentially.`\n",
    "\n",
    " and this has to be preprocessed to get the words and phrases."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af274c23491d6f52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classes = extract_classes_with_text(file_content)\n",
    "classes = remove_newlines_from_dict_keys(classes)\n",
    "classes = extract_divisions(classes)\n",
    "classes = refine_section_extraction(classes)\n",
    "classes = process_sections_with_no_title_key(classes)\n",
    "classes = transform_title_values(classes)\n",
    "write_data_to_json_file(classes, 'thesaurus.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.634378Z",
     "start_time": "2024-02-24T21:34:46.627295Z"
    }
   },
   "id": "343d5aa641a5f3d9",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    cleaned_text = re.sub(r'&c\\.?', '', cleaned_text)  # Remove \"&c\" and \"&c.\"\n",
    "    pattern = \".*?-- N\\.\"\n",
    "    cleaned_text = re.sub(pattern, '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\^', '', cleaned_text)\n",
    "    text_markers_pattern = r'\\b(?:Adv|adj|adv|Verb|Phr|V|v)\\.?\\b'\n",
    "    cleaned_text = re.sub(text_markers_pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    cleaned_text = re.sub(r'\\{[^}]*\\}', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
    "    tokens = [token.strip() for token in re.split('[,;.]', cleaned_text) if token.strip()]\n",
    "    return tokens\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.637805Z",
     "start_time": "2024-02-24T21:34:46.636180Z"
    }
   },
   "id": "292033f959e17e75",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for class_title, divisions in classes.items():\n",
    "    for division_title, sections in divisions.items():\n",
    "        for section_title, titles in sections.items():\n",
    "            for title, list_of_word_sections in titles.items():\n",
    "                for i, lst in enumerate(list_of_word_sections):\n",
    "                    cleaned_text = clean_text(lst)\n",
    "                    titles[title][i] = cleaned_text\n",
    "                    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:46.989399Z",
     "start_time": "2024-02-24T21:34:46.687098Z"
    }
   },
   "id": "f6eb543f88bda7b7",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also add a method that will remove the words that are not relevant because the llm missed them. We also remove duplicates per class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6e80fbe1fc828ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we write the data to a json file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9d1fb745504ab79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "write_data_to_json_file(classes, 'thesaurus_final.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:47.018618Z",
     "start_time": "2024-02-24T21:34:46.989543Z"
    }
   },
   "id": "c1abcf44557055e2",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
